{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "X = df.drop('Class', axis=1).values\n",
    "y = df['Class'].values\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_val, y_val = X[train_split:], y[train_split:]\n",
    "\n",
    "#Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Handle unbalenced dataset\n",
    "# class_counts = np.bincount(y_train)\n",
    "# class_weights = 1. / class_counts\n",
    "# sample_weights = class_weights[y_train]\n",
    "# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "#TensorDataset: Cette classe est utilisée pour créer un dataset a partir de tensor et itérer dessus.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "#DataLoader: Cette classe est utilisée pour charger les données en lots (batches) pendant l'entraînement du modèle.\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```class_counts = np.bincount(y_train)``` : Compte le nombre d'occurence dans chaque classe (bincount car il n'y a que deux classe)\n",
    "- ```class_weights = 1. / class_counts``` : Calcule les poids pour chaque classe en prenant l'inverse du nombre d'occurrences de chaque classe \n",
    "- ```sample_weights = class_weights[y_train]``` : Crée un tableau de poids pour chaque échantillon en fonction de sa classe \n",
    "- ```sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)```\n",
    "- ```train_loader = DataLoader(train_dataset, batch_size=1000, sampler=sampler)```: Le DataLoader en PyTorch est responsable de la création des batches d'échantillons pour l'entraînement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [978  22]\n",
      "class counts [1000]\n",
      "class counts [992   8]\n",
      "class counts [995   5]\n",
      "class counts [990  10]\n",
      "class counts [996   4]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [995   5]\n",
      "class counts [988  12]\n",
      "class counts [997   3]\n",
      "class counts [995   5]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [993   7]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [980  20]\n",
      "class counts [993   7]\n",
      "class counts [995   5]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [997   3]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [997   3]\n",
      "class counts [998   2]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [996   4]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [997   3]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [995   5]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [999   1]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [996   4]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [993   7]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [995   5]\n",
      "class counts [996   4]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [996   4]\n",
      "class counts [998   2]\n",
      "class counts [993   7]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [992   8]\n",
      "class counts [977  23]\n",
      "class counts [989  11]\n",
      "class counts [997   3]\n",
      "class counts [997   3]\n",
      "class counts [983  17]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [997   3]\n",
      "class counts [999   1]\n",
      "class counts [995   5]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [1000]\n",
      "class counts [997   3]\n",
      "class counts [997   3]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [997   3]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [999   1]\n",
      "class counts [998   2]\n",
      "class counts [998   2]\n",
      "class counts [996   4]\n",
      "class counts [1000]\n",
      "class counts [1000]\n",
      "class counts [998   2]\n",
      "class counts [845]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    _, labels = batch\n",
    "    print('class counts', np.bincount(labels.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoader :\n",
    "DataLoader est un autre utilitaire de PyTorch qui permet de charger des datasets de manière efficace en créant des minibatches d'échantillons. Il gère également le mélange (shuffling) et l'échantillonnage des données.\n",
    "- train_loader :\n",
    "train_loader est un DataLoader pour le dataset d'entraînement (train_dataset).\n",
    "- batch_size=32 :\n",
    " Les données sont chargées en minibatches de 32 échantillons.\n",
    "- sampler=sampler : \n",
    "Utilise un WeightedRandomSampler pour équilibrer les classes déséquilibrées lors de la sélection des échantillons pour chaque batch.\n",
    "Cela permet d'augmenter la probabilité que les classes minoritaires soient bien représentées dans chaque batch, améliorant ainsi l'apprentissage du modèle sur des datasets déséquilibrés.\n",
    "- val_loader :\n",
    "val_loader est un DataLoader pour le dataset de validation (val_dataset).\n",
    "- batch_size=32 : Les données sont chargées en minibatches de 32 échantillons.\n",
    "- shuffle=True : Les échantillons sont mélangés (shuffled) aléatoirement avant d'être divisés en batches.\n",
    "Le mélange des données est généralement utilisé pour le dataset de validation pour éviter que l'ordre des données n'affecte les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierCardModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ClassifierCardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "model = ClassifierCardModel(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, labels in train_loader: \n",
    "#     print(inputs, labels)\n",
    "#     print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 4.434514903539502, Val Loss: 4.515296961131849, Accuracy: 99.86833327481479, F1 Train: 0.0016839741790625876, F1 Val: 0.9980254328108966\n",
      "Epoch 2/20, Train Loss: 3.000717293878675, Val Loss: 2.324770638817235, Accuracy: 99.86833327481479, F1 Train: 0.009799554565701559, F1 Val: 0.9980254328108966\n",
      "Epoch 3/20, Train Loss: 12.215949920153147, Val Loss: 14.40355906570167, Accuracy: 99.86833327481479, F1 Train: 0.0014114326040931546, F1 Val: 0.9980254328108966\n",
      "Epoch 4/20, Train Loss: 4.9940619443526915, Val Loss: 2.1874930649472955, Accuracy: 99.86833327481479, F1 Train: 0.0, F1 Val: 0.9980254328108966\n",
      "Epoch 5/20, Train Loss: 4.455466319124516, Val Loss: 3.5555000137864496, Accuracy: 99.86833327481479, F1 Train: 0.004457652303120356, F1 Val: 0.9980254328108966\n",
      "Epoch 6/20, Train Loss: 9.273927323333657, Val Loss: 32.658645395647014, Accuracy: 99.86833327481479, F1 Train: 0.01995841995841996, F1 Val: 0.9980254328108966\n",
      "Epoch 7/20, Train Loss: 14.421635030981218, Val Loss: 16.393262260838558, Accuracy: 99.86833327481479, F1 Train: 0.0, F1 Val: 0.9980254328108966\n",
      "Epoch 8/20, Train Loss: 6.39499488335691, Val Loss: 5.404776330579791, Accuracy: 99.86833327481479, F1 Train: 0.0, F1 Val: 0.9980254328108966\n",
      "Epoch 9/20, Train Loss: 5.3665134019398115, Val Loss: 23.557242075602215, Accuracy: 99.86833327481479, F1 Train: 0.0056457304163726185, F1 Val: 0.9980254328108966\n",
      "Epoch 10/20, Train Loss: 12.708399255314777, Val Loss: 22.557958100971423, Accuracy: 99.86833327481479, F1 Train: 0.0013333333333333333, F1 Val: 0.9980254328108966\n",
      "Epoch 11/20, Train Loss: 6.576783739716599, Val Loss: 0.5975106263598591, Accuracy: 99.83673326077034, F1 Train: 0.0, F1 Val: 0.9978674078248355\n",
      "Epoch 12/20, Train Loss: 8.094427439523265, Val Loss: 37.854826174284284, Accuracy: 99.86833327481479, F1 Train: 0.07715330894579316, F1 Val: 0.9980254328108966\n",
      "Epoch 13/20, Train Loss: 16.26117076071208, Val Loss: 17.73408044848526, Accuracy: 99.86833327481479, F1 Train: 0.0, F1 Val: 0.9980254328108966\n",
      "Epoch 14/20, Train Loss: 5.9409802570416215, Val Loss: 3.117667846512376, Accuracy: 99.86833327481479, F1 Train: 0.004728132387706856, F1 Val: 0.9980254328108966\n",
      "Epoch 15/20, Train Loss: 0.6485052295909067, Val Loss: 5.433594628384239, Accuracy: 99.86833327481479, F1 Train: 0.37809647979139505, F1 Val: 0.9980254328108966\n",
      "Epoch 16/20, Train Loss: 0.7221651011473861, Val Loss: 18.30419777987296, Accuracy: 99.86833327481479, F1 Train: 0.10201511335012595, F1 Val: 0.9980254328108966\n",
      "Epoch 17/20, Train Loss: 24.60517465225176, Val Loss: 31.491662276418584, Accuracy: 99.86833327481479, F1 Train: 0.004739336492890996, F1 Val: 0.9980254328108966\n",
      "Epoch 18/20, Train Loss: 13.848371674094285, Val Loss: 16.208337767082348, Accuracy: 99.86833327481479, F1 Train: 0.004750593824228029, F1 Val: 0.9980254328108966\n",
      "Epoch 19/20, Train Loss: 6.034209624194262, Val Loss: 5.134178429319148, Accuracy: 99.86833327481479, F1 Train: 0.004705882352941176, F1 Val: 0.9980254328108966\n",
      "Epoch 20/20, Train Loss: 0.9837334942022898, Val Loss: 8.082228058262876, Accuracy: 99.86833327481479, F1 Train: 0.2838137472283814, F1 Val: 0.9980254328108966\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardfraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
